{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fingerprint Identification System"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-24T20:05:27.191508Z","iopub.status.busy":"2022-04-24T20:05:27.190957Z","iopub.status.idle":"2022-04-24T20:05:35.481655Z","shell.execute_reply":"2022-04-24T20:05:35.480594Z","shell.execute_reply.started":"2022-04-24T20:05:27.191422Z"},"trusted":true},"outputs":[],"source":["# OS\n","import os\n","\n","# Arrays\n","import numpy as np \n","\n","# Tensorflow and Keras\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import load_model\n","\n","# Sklearn\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","# Math\n","import math\n","\n","# Plots\n","import matplotlib as mpl\n","mpl.rc('image', cmap='gray') # set color map to gray when plotting images\n","from matplotlib import pyplot as plt \n","\n","# Fix seeds and create tensorflow session for reproducible results\n","SEED = 42\n","np.random.seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","tf.random.set_seed(SEED)\n","from keras import backend as K\n","session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n","sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n","tf.compat.v1.keras.backend.set_session(sess)"]},{"cell_type":"markdown","metadata":{},"source":["## Load Strategy for TPU, GPU or CPU Acceleration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:35.484401Z","iopub.status.busy":"2022-04-24T20:05:35.484135Z","iopub.status.idle":"2022-04-24T20:05:35.49568Z","shell.execute_reply":"2022-04-24T20:05:35.49482Z","shell.execute_reply.started":"2022-04-24T20:05:35.48437Z"},"trusted":true},"outputs":[],"source":["try:\n","    # TPU detection\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # By default, GPU or CPU\n","    strategy = tf.distribute.get_strategy()"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:35.497855Z","iopub.status.busy":"2022-04-24T20:05:35.497576Z","iopub.status.idle":"2022-04-24T20:05:36.124739Z","shell.execute_reply":"2022-04-24T20:05:36.123738Z","shell.execute_reply.started":"2022-04-24T20:05:35.497805Z"},"trusted":true},"outputs":[],"source":["train_images_file = '/kaggle/input/fingerprint-dataset-for-fvc2000-db4-b/dataset_FVC2000_DB4_B/dataset/np_data/img_train.npy';\n","train_labels_file = '/kaggle/input/fingerprint-dataset-for-fvc2000-db4-b/dataset_FVC2000_DB4_B/dataset/np_data/label_train.npy';\n","images_data = np.load('/kaggle/input/fingerprint-dataset-for-fvc2000-db4-b/dataset_FVC2000_DB4_B/dataset/np_data/img_train.npy')\n","labels_data = np.load('/kaggle/input/fingerprint-dataset-for-fvc2000-db4-b/dataset_FVC2000_DB4_B/dataset/np_data/label_train.npy')"]},{"cell_type":"markdown","metadata":{},"source":["10 classes of 80 samples each"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:36.127578Z","iopub.status.busy":"2022-04-24T20:05:36.127216Z","iopub.status.idle":"2022-04-24T20:05:36.141051Z","shell.execute_reply":"2022-04-24T20:05:36.139936Z","shell.execute_reply.started":"2022-04-24T20:05:36.127529Z"},"trusted":true},"outputs":[],"source":["np.unique(labels_data, return_counts=True) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:36.143563Z","iopub.status.busy":"2022-04-24T20:05:36.142961Z","iopub.status.idle":"2022-04-24T20:05:36.40287Z","shell.execute_reply":"2022-04-24T20:05:36.40182Z","shell.execute_reply.started":"2022-04-24T20:05:36.143513Z"},"trusted":true},"outputs":[],"source":["plt.imshow(images_data[0]) # plot a sample"]},{"cell_type":"markdown","metadata":{},"source":["## Configuration"]},{"cell_type":"markdown","metadata":{},"source":["Hyperparameters for the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:36.404801Z","iopub.status.busy":"2022-04-24T20:05:36.404549Z","iopub.status.idle":"2022-04-24T20:05:36.410566Z","shell.execute_reply":"2022-04-24T20:05:36.409821Z","shell.execute_reply.started":"2022-04-24T20:05:36.404755Z"},"trusted":true},"outputs":[],"source":["params = dict()\n","params['image_size'] = (160, 160, 3) # To resize the image\n","params['num_classes'] = 10 # Number of classes\n","params['max_epochs'] = 75 # Number of epochs for training the model\n","params['batch_size'] = 1 # Low batch takes more time to run but gives more weight to the stochastic properties of SGD\n","params['lr'] = 0.001 # Learning rate\n","params['seed'] = SEED # Seed for reproducibility\n","params['validation_size'] = 0.25 #S ize of validation set"]},{"cell_type":"markdown","metadata":{},"source":["## Train Validation Split"]},{"cell_type":"markdown","metadata":{},"source":["Split the train data into a train and validation set in a stratified way"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:21.386109Z","iopub.status.busy":"2022-04-22T15:17:21.385592Z","iopub.status.idle":"2022-04-22T15:17:21.408521Z","shell.execute_reply":"2022-04-22T15:17:21.407805Z","shell.execute_reply.started":"2022-04-22T15:17:21.38607Z"},"trusted":true},"outputs":[],"source":["train_images, validation_images, train_labels, validation_labels = train_test_split(images_data, \n","                                                                                    labels_data, \n","                                                                                    test_size=params['validation_size'], \n","                                                                                    random_state=params['seed'],\n","                                                                                    stratify=labels_data)\n","print(f\"Train set length: {len(train_images)}\")\n","print(f\"Validation set length: {len(validation_images)}\")\n","print(f\"Train set -> number of unique labels: {np.unique(train_labels, return_counts=True)}\")\n","print(f\"Validation set -> number of unique labels: {np.unique(validation_labels, return_counts=True)}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:36.412248Z","iopub.status.busy":"2022-04-24T20:05:36.411857Z","iopub.status.idle":"2022-04-24T20:05:36.428056Z","shell.execute_reply":"2022-04-24T20:05:36.427218Z","shell.execute_reply.started":"2022-04-24T20:05:36.412218Z"},"trusted":true},"outputs":[],"source":["class DataLoader(keras.utils.Sequence):\n","    def __init__(self, images, labels=None, params=None, batch_size=32, shuffle=False):\n","        self.images = images.astype(np.float32) / 255. # Scale the images to range [0, 1]\n","        self.images = np.repeat(self.images, 3, axis=-1) # convert from grayscale to RGB\n","        self.labels = labels \n","        self.batch_size = batch_size\n","        self.train = (labels is not None)\n","        if shuffle == True: # Shuffle the dataset\n","            if self.train:\n","                self.images, self.labels = sklearn.utils.shuffle(self.images, self.labels)\n","            else:\n","                self.images = sklearn.utils.shuffle(self.images)\n","                \n","        if params != None: \n","            self.images = tf.image.resize(self.images, params['image_size'][:2]) # Resize image\n","\n","    def __len__(self): \n","        'Get length of the data loader in number of batches'\n","        return int(np.floor(len(self.images) / self.batch_size)) # floor the size (excludes the last batch if it is incomplete)\n","\n","    def __getitem__(self, index):\n","        'Retrieve a specific batch of data'\n","        images_batch = self.images[index*self.batch_size:(index+1)*self.batch_size]\n","        if self.train:\n","            labels_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size, 0]\n","        \n","        if self.train: \n","            return (images_batch, labels_batch)\n","        return (images_batch, -np.ones(images_batch.shape[0])) # if test set, we do not have any labels"]},{"cell_type":"markdown","metadata":{},"source":["## Plot Batch of Samples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T18:24:16.968574Z","iopub.status.busy":"2022-04-24T18:24:16.968307Z","iopub.status.idle":"2022-04-24T18:24:16.976445Z","shell.execute_reply":"2022-04-24T18:24:16.975763Z","shell.execute_reply.started":"2022-04-24T18:24:16.968544Z"},"trusted":true},"outputs":[],"source":["def plot_batch(images_batch, labels_batch, predicted_labels=[], cols=5, figsize=(24, 6)):\n","    'Plot a batch of samples with its corresponding labels. Green labels for correctly predicted outputs, red otherwise'\n","    rows = int(np.ceil(len(labels_batch) / cols))\n","    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=figsize)\n","    i = 0\n","    for image, label in zip(images_batch, labels_batch):\n","        title = predicted_labels[i] + ' | ' + label if predicted_labels else label\n","        color = \"green\" if not predicted_labels or label == predicted_labels[i] else \"red\"\n","        ax.ravel()[i].imshow(image) #np.transpose(image, (1, 2, 0))\n","        ax.ravel()[i].set_title(title, color=color)\n","        ax.ravel()[i].set_axis_off()\n","        i += 1\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize a batch of fingerprints with their labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:23.716023Z","iopub.status.busy":"2022-04-22T15:17:23.715354Z","iopub.status.idle":"2022-04-22T15:17:25.609546Z","shell.execute_reply":"2022-04-22T15:17:25.608004Z","shell.execute_reply.started":"2022-04-22T15:17:23.715979Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_images, train_labels, params=params, batch_size=20, shuffle=True)\n","batch = train_loader[0]\n","plot_batch(batch[0], batch[1], cols=10)"]},{"cell_type":"markdown","metadata":{},"source":["## Train & Validation Data Loader"]},{"cell_type":"markdown","metadata":{},"source":["The train and validation data loaders allow to retrieve batch of samples for training a neural network"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:25.61126Z","iopub.status.busy":"2022-04-22T15:17:25.610905Z","iopub.status.idle":"2022-04-22T15:17:26.272581Z","shell.execute_reply":"2022-04-22T15:17:26.271807Z","shell.execute_reply.started":"2022-04-22T15:17:25.611228Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_images, train_labels, params=params, batch_size=params['batch_size'], shuffle=True)\n","validation_loader = DataLoader(validation_images, validation_labels, params=params, batch_size=params['batch_size'], shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Image Classification Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:28.567438Z","iopub.status.busy":"2022-04-22T15:17:28.56678Z","iopub.status.idle":"2022-04-22T15:17:31.82435Z","shell.execute_reply":"2022-04-22T15:17:31.823628Z","shell.execute_reply.started":"2022-04-22T15:17:28.567393Z"},"trusted":true},"outputs":[],"source":["import tensorflow_addons as tfa\n","with strategy.scope():\n","    # Load as backbone a topless pretrained ResNet50V2\n","    pretrained_model = tf.keras.applications.ResNet50V2(\n","        include_top=False,\n","        weights=\"imagenet\",\n","        input_tensor=None,\n","        input_shape=None,\n","        pooling=None,\n","        classes=params['num_classes'],\n","        classifier_activation=\"softmax\",\n","    )\n","    \n","    # Fix the backbone layer's parameters, we will not train them\n","    for layer in pretrained_model.layers:\n","        layer.trainable = False\n","    \n","    image = tf.keras.layers.Input(shape = params['image_size'])\n","    print(image.shape)\n","    x = pretrained_model(image)\n","    print(x.shape)\n","    # Global Average Pooling to reduce the number of dimensions of the features\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x) \n","    print(x.shape)\n","    # A dense layer to be the remaining features to the number of classes to predict\n","    x = tf.keras.layers.Dense(params['num_classes'])(x) \n","    print(x.shape)\n","    # A softmax layer to convert outputs into probability estimates\n","    output = tf.keras.layers.Softmax(dtype='float32')(x)\n","    print(output.shape)\n","    model = tf.keras.models.Model(inputs = [image], outputs = [output])   "]},{"cell_type":"markdown","metadata":{},"source":["## Loss, Performance Metric, Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:31.826257Z","iopub.status.busy":"2022-04-22T15:17:31.82602Z","iopub.status.idle":"2022-04-22T15:17:31.846512Z","shell.execute_reply":"2022-04-22T15:17:31.845875Z","shell.execute_reply.started":"2022-04-22T15:17:31.826225Z"},"trusted":true},"outputs":[],"source":["with strategy.scope():\n","    # Cross-Entropy Loss\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    \n","    # Adam optimizer\n","    optimizer = tf.keras.optimizers.Adam(learning_rate = params['lr'])\n","\n","#     def get_lr_metric(optimizer):\n","#         def lr(y_true, y_pred):\n","#             return optimizer._decayed_lr(tf.float32)\n","#         return lr\n","\n","#     lr_metric = get_lr_metric(optimizer)\n","\n","    # Accuracy Metric\n","    accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","    metrics = [accuracy]#, lr_metric] \n","    \n","    # Compile the model\n","    model.compile(optimizer=optimizer,\n","                  loss=loss,\n","                  metrics=metrics)"]},{"cell_type":"markdown","metadata":{},"source":["## Callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T16:04:58.789804Z","iopub.status.busy":"2022-04-22T16:04:58.789558Z","iopub.status.idle":"2022-04-22T16:04:58.794965Z","shell.execute_reply":"2022-04-22T16:04:58.794268Z","shell.execute_reply.started":"2022-04-22T16:04:58.789776Z"},"trusted":true},"outputs":[],"source":["callbacks = []"]},{"cell_type":"markdown","metadata":{},"source":["### Scheduler"]},{"cell_type":"markdown","metadata":{},"source":["Decrease the learning rate by exponential decay"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:31.848226Z","iopub.status.busy":"2022-04-22T15:17:31.847751Z","iopub.status.idle":"2022-04-22T15:17:31.853424Z","shell.execute_reply":"2022-04-22T15:17:31.85268Z","shell.execute_reply.started":"2022-04-22T15:17:31.848189Z"},"trusted":true},"outputs":[],"source":["scheduler = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=params['lr'],\n","                                                           decay_steps=1,\n","                                                           decay_rate=0.99,\n","                                                           staircase=True)\n","scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","callbacks.append(scheduler_callback)"]},{"cell_type":"markdown","metadata":{},"source":["### Model Checkpoints"]},{"cell_type":"markdown","metadata":{},"source":["Save the model with the best accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:32.212898Z","iopub.status.busy":"2022-04-22T15:17:32.212053Z","iopub.status.idle":"2022-04-22T15:17:32.219036Z","shell.execute_reply":"2022-04-22T15:17:32.218094Z","shell.execute_reply.started":"2022-04-22T15:17:32.212855Z"},"trusted":true},"outputs":[],"source":["checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","                                            './model/fingerprint-recognition.h5',\n","                                            monitor='val_sparse_categorical_accuracy',#'val_loss',\n","                                            verbose=0,\n","                                            save_best_only=True,\n","                                            save_weights_only=False,\n","                                            mode='auto',\n","                                            save_freq='epoch',\n","                                            options=None,\n","                                            initial_value_threshold=None)\n","callbacks.append(checkpoint_callback)"]},{"cell_type":"markdown","metadata":{},"source":["## Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:17:34.038941Z","iopub.status.busy":"2022-04-22T15:17:34.038198Z","iopub.status.idle":"2022-04-22T15:28:39.461119Z","shell.execute_reply":"2022-04-22T15:28:39.460401Z","shell.execute_reply.started":"2022-04-22T15:17:34.038879Z"},"trusted":true},"outputs":[],"source":["history = model.fit(train_loader, \n","                    validation_data=validation_loader,\n","                    epochs = params['max_epochs'],\n","                    batch_size = params['batch_size'],\n","                    callbacks = callbacks)"]},{"cell_type":"markdown","metadata":{},"source":["### Plot Losses and Performance Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:51:47.440877Z","iopub.status.busy":"2022-04-22T15:51:47.440632Z","iopub.status.idle":"2022-04-22T15:51:47.950504Z","shell.execute_reply":"2022-04-22T15:51:47.949821Z","shell.execute_reply.started":"2022-04-22T15:51:47.440849Z"},"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize=(10, 5))\n","#print(history.history.keys())\n","\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.savefig('./nn_fingerprint_loss.png')\n","plt.show()\n","\n","fig = plt.figure(figsize=(10, 5))\n","plt.plot(history.history['sparse_categorical_accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_sparse_categorical_accuracy'], label='Validation Accuracy')\n","plt.title('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.savefig('./nn_fingerprint_accuracy.png')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-22T15:47:06.729399Z","iopub.status.busy":"2022-04-22T15:47:06.72915Z","iopub.status.idle":"2022-04-22T15:47:06.747492Z","shell.execute_reply":"2022-04-22T15:47:06.746612Z","shell.execute_reply.started":"2022-04-22T15:47:06.729372Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# NN-Based Fingerprint Identification System"]},{"cell_type":"markdown","metadata":{},"source":["Let's now build a fingerprint identification system based on the nn features extracted from the fingerprints"]},{"cell_type":"markdown","metadata":{},"source":["## Import Additional Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:36.429887Z","iopub.status.busy":"2022-04-24T20:05:36.429428Z","iopub.status.idle":"2022-04-24T20:05:36.895473Z","shell.execute_reply":"2022-04-24T20:05:36.89455Z","shell.execute_reply.started":"2022-04-24T20:05:36.429853Z"},"trusted":true},"outputs":[],"source":["import cv2\n","\n","import pandas as pd\n","\n","from pathlib import Path\n","\n","from tqdm.notebook import tqdm as tqdm_notebook"]},{"cell_type":"markdown","metadata":{},"source":["## Load Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:36.896969Z","iopub.status.busy":"2022-04-24T20:05:36.896705Z","iopub.status.idle":"2022-04-24T20:05:37.786161Z","shell.execute_reply":"2022-04-24T20:05:37.785182Z","shell.execute_reply.started":"2022-04-24T20:05:36.896937Z"},"trusted":true},"outputs":[],"source":["def read_DB(path):\n","    images = []\n","    labels = []\n","    imagePaths = sorted(Path(path).rglob(\"*.png\"))\n","    for imagePath in tqdm_notebook(imagePaths):\n","        image = cv2.imread(path + imagePath.name)\n","        if (len(image.shape) > 2):\n","            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        images.append(image)\n","        label = imagePath.stem[0:3]\n","        labels.append(label)\n","    return (images, labels)\n","\n","\n","# Read the fingerprint database\n","images_db, labels_db = read_DB('../input/NIST301/')\n","\n","# Save some metadata\n","n_imgs = len(images_db)\n","img_height, img_width = images_db[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:37.788491Z","iopub.status.busy":"2022-04-24T20:05:37.788246Z","iopub.status.idle":"2022-04-24T20:05:38.376072Z","shell.execute_reply":"2022-04-24T20:05:38.374971Z","shell.execute_reply.started":"2022-04-24T20:05:37.788461Z"},"trusted":true},"outputs":[],"source":["test_loader = DataLoader(np.expand_dims(np.array(images_db), -1), params=params, batch_size=len(images_db))"]},{"cell_type":"markdown","metadata":{},"source":["## Load Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:38.963826Z","iopub.status.busy":"2022-04-24T20:05:38.963553Z","iopub.status.idle":"2022-04-24T20:05:42.384263Z","shell.execute_reply":"2022-04-24T20:05:42.383117Z","shell.execute_reply.started":"2022-04-24T20:05:38.963796Z"},"trusted":true},"outputs":[],"source":["fingerprint_recognition_model = load_model('../input/fingerprint-recognition-dnn/fingerprint-recognition.h5');\n","# We remove the softmax layer because the purpose of this model is not to predict a class but to retrieve image embeddings\n","fingerprint_embedding_model = keras.models.Model(inputs=fingerprint_recognition_model.input, \n","                                                 outputs=fingerprint_recognition_model.layers[-2].output)"]},{"cell_type":"markdown","metadata":{},"source":["## Retrieve Test and Perpetrator Fringerprint Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:46.755239Z","iopub.status.busy":"2022-04-24T20:05:46.754919Z","iopub.status.idle":"2022-04-24T20:05:55.263492Z","shell.execute_reply":"2022-04-24T20:05:55.262633Z","shell.execute_reply.started":"2022-04-24T20:05:46.755206Z"},"trusted":true},"outputs":[],"source":["test_embeddings = fingerprint_embedding_model(test_loader[0][0])\n","perpetrator_embedding = test_embeddings[-1]\n","test_embeddings = test_embeddings[0:-1]"]},{"cell_type":"markdown","metadata":{},"source":["## Similarity Measure"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:05:55.26528Z","iopub.status.busy":"2022-04-24T20:05:55.265038Z","iopub.status.idle":"2022-04-24T20:05:55.269738Z","shell.execute_reply":"2022-04-24T20:05:55.268998Z","shell.execute_reply.started":"2022-04-24T20:05:55.265252Z"},"trusted":true},"outputs":[],"source":["mss = lambda x,y: 1/(1+np.square(x-y).mean())"]},{"cell_type":"markdown","metadata":{},"source":["## Helper Functions"]},{"cell_type":"markdown","metadata":{},"source":["Plot a sequence of images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:07:47.348992Z","iopub.status.busy":"2022-04-24T20:07:47.348661Z","iopub.status.idle":"2022-04-24T20:07:47.358948Z","shell.execute_reply":"2022-04-24T20:07:47.357828Z","shell.execute_reply.started":"2022-04-24T20:07:47.348956Z"},"trusted":true},"outputs":[],"source":["# Helper functions\n","def plot_image_sequence(data, n, imgs_per_row=7, figsize=(10,10), cmap='gray'):\n","    n_rows = 1 + int(n/(imgs_per_row+1))\n","    n_cols = min(imgs_per_row, n)\n","\n","    f,ax = plt.subplots(n_rows,n_cols, figsize=(figsize[0]*n_cols,figsize[1]*n_rows))\n","    for i in range(n):\n","        if n == 1:\n","            ax.imshow(data[i], cmap=cmap)\n","        elif n_rows > 1:\n","            ax[int(i/imgs_per_row),int(i%imgs_per_row)].imshow(data[i], cmap=cmap)\n","        else:\n","            ax[int(i%n)].imshow(data[i], cmap=cmap)\n","    plt.show()\n","    return f, ax"]},{"cell_type":"markdown","metadata":{},"source":["Construct a table of similarity scores between a target image and many candidate images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:06:01.327948Z","iopub.status.busy":"2022-04-24T20:06:01.32759Z","iopub.status.idle":"2022-04-24T20:06:01.337474Z","shell.execute_reply":"2022-04-24T20:06:01.336745Z","shell.execute_reply.started":"2022-04-24T20:06:01.327913Z"},"trusted":true},"outputs":[],"source":["def constructSimilarityTable(org_img, img_db, labels, dist_func):\n","    #dist_func is the function that computes the distance between two images\n","    data=[]\n","    for i,img in enumerate(img_db):\n","        data.append([\n","            labels[i],\n","            dist_func(org_img, img)])\n","    assert (len(data) == len(img_db))\n","    return pd.DataFrame(data, columns=['id', 'score'])"]},{"cell_type":"markdown","metadata":{},"source":["## Compute the similarity scores \n","between the perpetrator fingerprint embeddings and all candidate fingerprint embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:06:03.330278Z","iopub.status.busy":"2022-04-24T20:06:03.329712Z","iopub.status.idle":"2022-04-24T20:06:03.362189Z","shell.execute_reply":"2022-04-24T20:06:03.361409Z","shell.execute_reply.started":"2022-04-24T20:06:03.330217Z"},"trusted":true},"outputs":[],"source":["sim_tb_nn = constructSimilarityTable(perpetrator_embedding, test_embeddings, labels_db, mss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:06:05.379244Z","iopub.status.busy":"2022-04-24T20:06:05.378669Z","iopub.status.idle":"2022-04-24T20:06:05.806736Z","shell.execute_reply":"2022-04-24T20:06:05.805832Z","shell.execute_reply.started":"2022-04-24T20:06:05.379178Z"},"trusted":true},"outputs":[],"source":["sim_tb_nn = sim_tb_nn.sort_values(by='score', ascending=False)\n","ids,scores = sim_tb_nn.values[:,0], sim_tb_nn.values[:,1]\n","fig = plt.figure(figsize=(12, 6))\n","plt.plot(ids,scores)\n","plt.xticks(np.arange(0,100,3), ids[np.arange(0,100,3)], rotation=45)\n","plt.title('Highest Score ID: ' + ids[0]);\n","plt.xlabel('Fingerprint ID')\n","plt.ylabel('Fingerprint NN Features Match Score')\n","fig.savefig('fingerprint-nn-features-match-scores.png')\n","\n","[print(i+1, sim_tb_nn.iloc[i,0], f\"{sim_tb_nn.iloc[i,1]:.5f}\") for i in range(10)];"]},{"cell_type":"markdown","metadata":{},"source":["Let's have a look at the best matches for the perpetrator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:06:08.550436Z","iopub.status.busy":"2022-04-24T20:06:08.549611Z","iopub.status.idle":"2022-04-24T20:06:08.775381Z","shell.execute_reply":"2022-04-24T20:06:08.774451Z","shell.execute_reply.started":"2022-04-24T20:06:08.550378Z"},"trusted":true},"outputs":[],"source":["# Perpetrator's fingerprint\n","plt.imshow(images_db[-1], cmap='gray')"]},{"cell_type":"markdown","metadata":{},"source":["14 best matches: the 6 first do correspond to the perpetrator's fingerprint."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-24T20:07:59.936641Z","iopub.status.busy":"2022-04-24T20:07:59.936271Z","iopub.status.idle":"2022-04-24T20:08:04.470455Z","shell.execute_reply":"2022-04-24T20:08:04.469737Z","shell.execute_reply.started":"2022-04-24T20:07:59.936601Z"},"trusted":true},"outputs":[],"source":["fig, ax = plot_image_sequence([images_db[int(sim_tb_nn.iloc[i,0])-1] for i in range(14)], 14)\n","fig.savefig('nn-best-fingerprint-matches.png')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
